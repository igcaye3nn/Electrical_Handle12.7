#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
UAV20241021 æ¸©åº¦æ£€æµ‹ç³»ç»Ÿä¸»æ§åˆ¶æ¨¡å—

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. åè°ƒæ‰€æœ‰å­æ¨¡å—çš„è¿è¡Œ
2. æä¾›ç»Ÿä¸€çš„ç³»ç»Ÿæ¥å£
3. ç®¡ç†æ¸©åº¦æ•°æ®é©±åŠ¨çš„å®Œæ•´æµç¨‹
4. åœ¨jyc_condaç¯å¢ƒä¸­è¿è¡Œ

Author: AI Assistant
Date: 2025-09-19
Environment: jyc_conda
"""

import os
import sys
import json
import logging
import argparse
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
import os
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(CURRENT_DIR)
sys.path.append(CURRENT_DIR)
sys.path.append(os.path.join(ROOT_DIR, 'yolov11-OBB-main'))

class ThermalDetectionSystem:
    """æ¸©åº¦æ£€æµ‹ç³»ç»Ÿä¸»æ§åˆ¶å™¨"""
    
    def __init__(self, config_path: str = None):
        """
        åˆå§‹åŒ–ç³»ç»Ÿæ§åˆ¶å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        if config_path is None:
            config_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        self.config_path = config_path
        self.config = self._load_config()
        self.setup_logging()
        self.check_environment()
        
    def _load_config(self) -> dict:
        """åŠ è½½ç³»ç»Ÿé…ç½®"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> dict:
        """è·å–é»˜è®¤é…ç½®"""
        current_dir = os.path.dirname(os.path.abspath(__file__))
        root_dir = os.path.dirname(current_dir)
        return {
            "project_name": "UAV20241021_thermal_detection",
            "paths": {
                "project_root": current_dir,
                "data_root": os.path.join(root_dir, "data", "20250915_è¾“ç”µçº¢å¤–æ•°æ®é›†", "UAV20241021")
            },
            "environment": {
                "conda_env": "jyc_conda",
                "cuda_device": "cuda:2"
            }
        }
    
    def setup_logging(self):
        """è®¾ç½®ç³»ç»Ÿæ—¥å¿—"""
        log_file = os.path.join(self.config['paths']['project_root'], 'system.log')
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger('ThermalDetectionSystem')
    
    def check_environment(self):
        """æ£€æŸ¥è¿è¡Œç¯å¢ƒ"""
        self.logger.info("ğŸ” æ£€æŸ¥è¿è¡Œç¯å¢ƒ...")
        
        # æ£€æŸ¥Pythonç¯å¢ƒ
        conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'unknown')
        self.logger.info(f"Condaç¯å¢ƒ: {conda_env}")
        
        if conda_env != self.config['environment']['conda_env']:
            self.logger.warning(f"å½“å‰ç¯å¢ƒ {conda_env} ä¸é…ç½®ä¸ç¬¦ {self.config['environment']['conda_env']}")
        
        # è‡ªåŠ¨æ£€æµ‹å’Œé…ç½®è®¾å¤‡
        self._auto_detect_device()
        
        # æ£€æŸ¥æ•°æ®ç›®å½•
        data_root = self.config['paths']['data_root']
        if os.path.exists(data_root):
            self.logger.info(f"âœ… æ•°æ®ç›®å½•å­˜åœ¨: {data_root}")
        else:
            self.logger.error(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_root}")
    
    def _auto_detect_device(self):
        """è‡ªåŠ¨æ£€æµ‹å¹¶é…ç½®æœ€ä½³å¯ç”¨è®¾å¤‡"""
        try:
            import torch
            
            if torch.cuda.is_available():
                device_count = torch.cuda.device_count()
                self.logger.info(f"âœ… CUDAå¯ç”¨, å‘ç° {device_count} ä¸ªGPU")
                
                # æ£€æŸ¥é…ç½®çš„GPUæ˜¯å¦å¯ç”¨
                current_device = self.config['model_config']['device']
                if current_device.startswith('cuda:'):
                    target_gpu = int(current_device.split(':')[1])
                    if target_gpu < device_count:
                        try:
                            # å®é™…æµ‹è¯•GPUæ˜¯å¦å¯ç”¨
                            torch.cuda.set_device(target_gpu)
                            test_tensor = torch.tensor([1.0]).cuda(target_gpu)
                            _ = test_tensor + 1
                            
                            self.logger.info(f"âœ… ä½¿ç”¨é…ç½®çš„GPU: {current_device}")
                            self.config['environment']['cuda_device'] = current_device
                            return
                        except Exception as e:
                            self.logger.warning(f"âš ï¸  GPU {target_gpu} ä¸å¯ç”¨: {e}")
                
                # è‡ªåŠ¨é€‰æ‹©æœ€ä½³GPU (ä¼˜å…ˆ2-7ï¼Œç„¶å0-1)
                preferred_gpus = list(range(2, min(8, device_count))) + [0, 1]
                
                for gpu_id in preferred_gpus:
                    if gpu_id >= device_count:
                        continue
                    try:
                        torch.cuda.set_device(gpu_id)
                        test_tensor = torch.tensor([1.0]).cuda(gpu_id)
                        _ = test_tensor + 1
                        
                        # æ£€æŸ¥å†…å­˜
                        props = torch.cuda.get_device_properties(gpu_id)
                        memory_total = props.total_memory / 1024**3
                        memory_allocated = torch.cuda.memory_allocated(gpu_id) / 1024**3
                        memory_free = memory_total - memory_allocated
                        
                        if memory_free >= 2.0:  # è‡³å°‘2GBç©ºé—²å†…å­˜
                            best_device = f"cuda:{gpu_id}"
                            self.logger.info(f"ğŸ¯ è‡ªåŠ¨é€‰æ‹©GPU: {best_device} ({props.name}, ç©ºé—²:{memory_free:.1f}GB)")
                            self.config['model_config']['device'] = best_device
                            self.config['environment']['cuda_device'] = best_device
                            return
                            
                    except Exception:
                        continue
                
                # å¦‚æœæ‰€æœ‰GPUéƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªGPUä½œä¸ºå¤‡é€‰
                self.logger.warning("âš ï¸  æ‰€æœ‰ä¼˜é€‰GPUä¸å¯ç”¨ï¼Œä½¿ç”¨cuda:0ä½œä¸ºå¤‡é€‰")
                self.config['model_config']['device'] = "cuda:0"
                self.config['environment']['cuda_device'] = "cuda:0"
                
            else:
                # CUDAä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPU
                self.logger.warning("âš ï¸  CUDAä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°CPUæ¨¡å¼")
                self.config['model_config']['device'] = "cpu"
                self.config['environment']['cuda_device'] = "cpu"
                
                # CPUæ¨¡å¼ä¸‹è°ƒæ•´è®­ç»ƒå‚æ•°
                if self.config['model_config']['batch_size'] > 8:
                    original_batch = self.config['model_config']['batch_size']
                    self.config['model_config']['batch_size'] = 4
                    self.logger.info(f"ğŸ’¡ CPUæ¨¡å¼: batch_size {original_batch} â†’ 4")
                
        except ImportError:
            self.logger.warning("âš ï¸  PyTorchæœªå®‰è£…ï¼Œä½¿ç”¨CPUæ¨¡å¼")
            self.config['model_config']['device'] = "cpu"
            self.config['environment']['cuda_device'] = "cpu"
    
    def run_data_preprocessing(self):
        """è¿è¡Œæ•°æ®é¢„å¤„ç†"""
        self.logger.info("ğŸ“Š å¼€å§‹æ•°æ®é¢„å¤„ç†...")
        
        try:
            from data_preprocessing import ThermalDataPreprocessor
            
            preprocessor = ThermalDataPreprocessor(self.config_path)
            stats = preprocessor.process_all_data()
            
            self.logger.info(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ: {stats}")
            return stats
            
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
            return {"success": 0, "failed": 0}
    
    def run_model_training(self):
        """è¿è¡Œæ¨¡å‹è®­ç»ƒ"""
        self.logger.info("ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
        
        try:
            from model_training import ThermalYOLOTrainer
            
            trainer = ThermalYOLOTrainer(self.config_path)
            success = trainer.train_model()
            
            if success:
                self.logger.info("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
                return True
            else:
                self.logger.error("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹è®­ç»ƒå¼‚å¸¸: {e}")
            return False
    
    def run_model_evaluation(self):
        """è¿è¡Œæ¨¡å‹è¯„ä¼°å¹¶ç”ŸæˆJSONç»“æœ"""
        self.logger.info("ğŸ“Š å¼€å§‹æ¨¡å‹è¯„ä¼°...")
        
        try:
            from model_training import ThermalYOLOTrainer
            
            trainer = ThermalYOLOTrainer(self.config_path)
            success, json_path = trainer.evaluate_model()
            
            if success:
                self.logger.info(f"âœ… æ¨¡å‹è¯„ä¼°å®Œæˆï¼ŒJSONç»“æœä¿å­˜è‡³: {json_path}")
                print(f"ğŸ“„ JSONè¯„ä¼°ç»“æœä¿å­˜ä½ç½®: {json_path}")
                return json_path
            else:
                self.logger.error("âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹è¯„ä¼°å¼‚å¸¸: {e}")
            return None
    
    def run_inference(self, sample_names=None):
        """è¿è¡Œæ¨ç†æ£€æµ‹"""
        self.logger.info("ğŸ” å¼€å§‹æ¨ç†æ£€æµ‹...")
        
        try:
            from multimodal_inference import ThermalInferenceEngine
            
            inference_engine = ThermalInferenceEngine(self.config_path)
            results = inference_engine.batch_inference(sample_names)
            
            self.logger.info(f"âœ… æ¨ç†å®Œæˆï¼Œå¤„ç†äº† {len(results)} ä¸ªæ ·æœ¬")
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ æ¨ç†æ£€æµ‹å¼‚å¸¸: {e}")
            return []
    
    def run_visualization(self, inference_results):
        """è¿è¡Œç»“æœå¯è§†åŒ–"""
        self.logger.info("ğŸ¨ å¼€å§‹ç»“æœå¯è§†åŒ–...")
        
        try:
            from visualization import ThermalVisualization
            
            visualizer = ThermalVisualization(self.config_path)
            
            # å¯è§†åŒ–æ¯ä¸ªæ£€æµ‹ç»“æœï¼ˆåŒ…æ‹¬å¤±è´¥çš„ï¼‰
            saved_paths = []
            for result in inference_results:
                # ä¸ºæ‰€æœ‰æ ·æœ¬ç”Ÿæˆå¯è§†åŒ–ï¼Œä¸è®ºæˆåŠŸä¸å¦
                path = visualizer.visualize_detection_result(result)
                if path:
                    saved_paths.append(path)
            
            # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
            report_path = visualizer.create_summary_report(inference_results)
            if report_path:
                saved_paths.append(report_path)
            
            self.logger.info(f"âœ… å¯è§†åŒ–å®Œæˆï¼Œç”Ÿæˆäº† {len(saved_paths)} ä¸ªå›¾åƒ")
            return saved_paths
            
        except Exception as e:
            self.logger.error(f"âŒ å¯è§†åŒ–å¼‚å¸¸: {e}")
            return []
    
    def run_full_pipeline(self):
        """è¿è¡Œå®Œæ•´æ£€æµ‹æµç¨‹"""
        self.logger.info("ğŸŒ¡ï¸ å¼€å§‹æ¸©åº¦æ£€æµ‹å®Œæ•´æµç¨‹...")
        
        pipeline_start = datetime.now()
        
        # 1. æ•°æ®é¢„å¤„ç†
        print("\n" + "="*50)
        print("ğŸ“Š ç¬¬1æ­¥: æ¸©åº¦æ•°æ®é¢„å¤„ç†")
        print("="*50)
        preprocessing_stats = self.run_data_preprocessing()
        
        if preprocessing_stats['success'] == 0:
            self.logger.error("æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
            return False
        
        # 2. æ¨¡å‹è®­ç»ƒ
        print("\n" + "="*50)
        print("ğŸš€ ç¬¬2æ­¥: æ¸©åº¦æ¨¡å‹è®­ç»ƒ")
        print("="*50)
        training_success = self.run_model_training()
        
        if not training_success:
            self.logger.warning("æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¨ç†")
        
        # 3. æ¨ç†æ£€æµ‹
        print("\n" + "="*50)
        print("ğŸ” ç¬¬3æ­¥: æ¸©åº¦æ¨ç†æ£€æµ‹")
        print("="*50)
        inference_results = self.run_inference()
        
        if not inference_results:
            self.logger.error("æ¨ç†æ£€æµ‹å¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
            return False
        
        # 4. ç»“æœå¯è§†åŒ–
        print("\n" + "="*50)
        print("ğŸ¨ ç¬¬4æ­¥: ç»“æœå¯è§†åŒ–")
        print("="*50)
        visualization_paths = self.run_visualization(inference_results)
        
        # æµç¨‹æ€»ç»“
        pipeline_end = datetime.now()
        pipeline_duration = pipeline_end - pipeline_start
        
        print("\n" + "="*50)
        print("ğŸ‰ æ¸©åº¦æ£€æµ‹æµç¨‹å®Œæˆ!")
        print("="*50)
        
        success_count = len([r for r in inference_results if r.get('success', False)])
        total_detections = sum(r.get('detection_count', 0) for r in inference_results if r.get('success', False))
        
        summary = f"""
ğŸŒ¡ï¸ UAV20241021 æ¸©åº¦æ£€æµ‹ç³»ç»Ÿè¿è¡Œæ€»ç»“

ğŸ“Š æ•°æ®å¤„ç†:
  â€¢ æˆåŠŸå¤„ç†: {preprocessing_stats['success']} ä¸ªæ ·æœ¬
  â€¢ å¤±è´¥æ•°é‡: {preprocessing_stats['failed']} ä¸ªæ ·æœ¬

ğŸš€ æ¨¡å‹è®­ç»ƒ:
  â€¢ è®­ç»ƒçŠ¶æ€: {'âœ… æˆåŠŸ' if training_success else 'âš ï¸ å¤±è´¥/è·³è¿‡'}

ğŸ” æ¨ç†æ£€æµ‹:
  â€¢ æˆåŠŸæ¨ç†: {success_count} ä¸ªæ ·æœ¬
  â€¢ æ£€æµ‹ç›®æ ‡: {total_detections} ä¸ª
  â€¢ æ£€æµ‹æ–¹æ³•: ğŸŒ¡ï¸ æ¸©åº¦æ•°æ®é©±åŠ¨

ğŸ¨ å¯è§†åŒ–:
  â€¢ ç”Ÿæˆå›¾åƒ: {len(visualization_paths)} ä¸ª
  
â±ï¸ æ€»è€—æ—¶: {pipeline_duration}

ğŸ’¡ ç³»ç»Ÿç‰¹è‰²:
  â€¢ æ ¸å¿ƒ: æ¸©åº¦æ•°æ®è®­ç»ƒ+æ¨ç†
  â€¢ è¾…åŠ©: åŸå§‹å›¾åƒæ•ˆæœå¯¹æ¯”
  â€¢ ç¯å¢ƒ: jyc_conda + GPUåŠ é€Ÿ
  â€¢ åº”ç”¨: ç”µåŠ›è®¾å¤‡æ•…éšœé¢„è­¦
        """
        
        print(summary)
        self.logger.info("âœ… å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæˆ")
        
        return True

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='UAV20241021 æ¸©åº¦æ£€æµ‹ç³»ç»Ÿ')
    parser.add_argument('--mode', choices=['preprocess', 'train', 'eval', 'inference', 'visualize', 'full'], 
                       default='full', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--config', default=None, 
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤ä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„config.json)')
    
    args = parser.parse_args()
    
    print("ğŸŒ¡ï¸ UAV20241021 æ¸©åº¦æ£€æµ‹ç³»ç»Ÿ")
    print("=" * 50)
    print("ğŸ”§ ç¯å¢ƒ: jyc_conda")
    print("ğŸ–¥ï¸  GPU: è‡ªåŠ¨é€‰æ‹©ç©ºé—²GPU")
    print("ğŸ¯ æ ¸å¿ƒ: æ¸©åº¦æ•°æ®é©±åŠ¨æ£€æµ‹")
    print("ğŸ“¸ è¾…åŠ©: åŸå§‹å›¾åƒæ•ˆæœå¯¹æ¯”")
    print("=" * 50)
    
    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    system = ThermalDetectionSystem(args.config)
    
    # æ ¹æ®æ¨¡å¼è¿è¡Œ
    if args.mode == 'preprocess':
        system.run_data_preprocessing()
    elif args.mode == 'train':
        system.run_model_training()
    elif args.mode == 'eval':
        system.run_model_evaluation()
    elif args.mode == 'inference':
        results = system.run_inference()
        print(f"æ¨ç†å®Œæˆï¼Œå¤„ç†äº† {len(results)} ä¸ªæ ·æœ¬")
    elif args.mode == 'visualize':
        # éœ€è¦å…ˆæœ‰æ¨ç†ç»“æœ
        results = system.run_inference()
        system.run_visualization(results)
    elif args.mode == 'full':
        system.run_full_pipeline()

if __name__ == "__main__":
    main()
