#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
UAV20241021 æ¸©åº¦æ•°æ®é©±åŠ¨æ¨ç†æ£€æµ‹

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ä½¿ç”¨æ¸©åº¦æ•°æ®è¿›è¡Œå®é™…æ£€æµ‹æ¨ç†
2. åŠ è½½è®­ç»ƒå¥½çš„æ¸©åº¦æ£€æµ‹æ¨¡å‹
3. ç”Ÿæˆæ£€æµ‹ç»“æœå¹¶ä¿å­˜ä¸ºå¯è§†åŒ–å›¾åƒ
4. æ¸©åº¦æ•°æ®ä¸»å¯¼ï¼ŒåŸå§‹å›¾åƒä»…ç”¨äºå¯¹æ¯”å±•ç¤º

Author: AI Assistant
Date: 2025-09-19
Environment: jyc_conda
"""

import os
import sys
import json
import numpy as np
import cv2
import torch
import logging
from pathlib import Path
from typing import List, Dict, Tuple, Optional

# æ·»åŠ YOLOv11è·¯å¾„
import os
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(CURRENT_DIR)
sys.path.append(os.path.join(ROOT_DIR, 'yolov11-OBB-main'))

class ThermalInferenceEngine:
    """æ¸©åº¦æ•°æ®é©±åŠ¨æ¨ç†å¼•æ“"""
    
    def __init__(self, config_path: str = None):
        """
        åˆå§‹åŒ–æ¨ç†å¼•æ“
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        if config_path is None:
            config_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')
        self.config = self._load_config(config_path)
        
        # åˆå§‹åŒ–æ£€æµ‹å‚æ•°
        self.confidence_threshold = self.config['model_config'].get('confidence_threshold', 0.25)
        self.iou_threshold = self.config['model_config'].get('iou_threshold', 0.7)
        self.max_detections = self.config['model_config'].get('max_detections', 300)
        
        self.setup_environment()
        self.setup_logging()
        self.load_model()
        
    def _load_config(self, config_path: str) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> dict:
        """è·å–é»˜è®¤é…ç½®"""
        current_dir = os.path.dirname(os.path.abspath(__file__))
        root_dir = os.path.dirname(current_dir)
        return {
            "paths": {
                "project_root": current_dir,
                "data_root": os.path.join(root_dir, "data", "20250915_è¾“ç”µçº¢å¤–æ•°æ®é›†", "UAV20241021")
            },
            "model_config": {
                "device": "cuda:2"
            },
            "data_processing": {
                "input_size": [640, 512],
                "thermal_colormap": "COLORMAP_JET"
            }
        }
    
    def setup_environment(self):
        """è®¾ç½®æ¨ç†ç¯å¢ƒ"""
        print("ğŸ”§ è®¾ç½®æ¨ç†ç¯å¢ƒ...")
        
        # è®¾ç½®GPUè®¾å¤‡
        self.device = self.config['model_config']['device']
        if 'cuda' in self.device and torch.cuda.is_available():
            gpu_id = int(self.device.split(':')[1])
            torch.cuda.set_device(gpu_id)
            print(f"ğŸ–¥ï¸  ä½¿ç”¨GPU: {self.device}")
        else:
            self.device = 'cpu'
            print("ğŸ–¥ï¸  ä½¿ç”¨CPUæ¨ç†")
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        self.output_dir = os.path.join(self.config['paths']['project_root'], 'inference_results')
        os.makedirs(self.output_dir, exist_ok=True)
        
    def setup_logging(self):
        """è®¾ç½®æ¨ç†æ—¥å¿—"""
        log_file = os.path.join(self.config['paths']['project_root'], 'inference.log')
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            model_path = os.path.join(self.config['paths']['project_root'], 'best_thermal_model.pt')
            
            if not os.path.exists(model_path):
                self.logger.warning(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                self.logger.info("å°è¯•ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹...")
                model_path = 'yolo11s-obb.pt'
            
            from ultralytics import YOLO
            self.model = YOLO(model_path)
            self.model.to(self.device)
            
            self.logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
            
        except Exception as e:
            self.logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.model = None
    
    def load_temperature_data(self, temp_file_path: str) -> Optional[np.ndarray]:
        """
        åŠ è½½æ¸©åº¦æ•°æ®æ–‡ä»¶
        
        Args:
            temp_file_path: æ¸©åº¦æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ¸©åº¦æ•°æ®çŸ©é˜µæˆ–None
        """
        try:
            if not os.path.exists(temp_file_path):
                self.logger.warning(f"æ¸©åº¦æ–‡ä»¶ä¸å­˜åœ¨: {temp_file_path}")
                return None
                
            # å°è¯•ä¸åŒçš„åŠ è½½æ–¹å¼
            try:
                temp_data = np.loadtxt(temp_file_path)
            except:
                try:
                    with open(temp_file_path, 'r') as f:
                        lines = f.readlines()
                        temp_data = []
                        for line in lines:
                            row = [float(x) for x in line.strip().split()]
                            temp_data.append(row)
                        temp_data = np.array(temp_data)
                except:
                    temp_data = np.loadtxt(temp_file_path, delimiter=',')
            
            self.logger.info(f"æ¸©åº¦æ•°æ®åŠ è½½æˆåŠŸ: {temp_data.shape}")
            return temp_data
            
        except Exception as e:
            self.logger.error(f"æ¸©åº¦æ•°æ®åŠ è½½å¤±è´¥ {temp_file_path}: {e}")
            return None
    
    def convert_thermal_to_inference_image(self, temp_data: np.ndarray) -> np.ndarray:
        """
        å°†æ¸©åº¦æ•°æ®è½¬æ¢ä¸ºæ¨ç†ç”¨çƒ­åŠ›å›¾
        
        Args:
            temp_data: æ¸©åº¦æ•°æ®çŸ©é˜µ
            
        Returns:
            çƒ­åŠ›å›¾å›¾åƒ (BGRæ ¼å¼)
        """
        try:
            # æ•°æ®å½’ä¸€åŒ–
            temp_normalized = (temp_data - temp_data.min()) / (temp_data.max() - temp_data.min())
            temp_uint8 = (temp_normalized * 255).astype(np.uint8)
            
            # åº”ç”¨é¢œè‰²æ˜ å°„
            colormap = getattr(cv2, self.config['data_processing']['thermal_colormap'])
            thermal_image = cv2.applyColorMap(temp_uint8, colormap)
            
            # è°ƒæ•´å°ºå¯¸
            target_size = tuple(self.config['data_processing']['input_size'])
            thermal_image = cv2.resize(thermal_image, target_size)
            
            return thermal_image
            
        except Exception as e:
            self.logger.error(f"æ¸©åº¦æ•°æ®è½¬æ¢å¤±è´¥: {e}")
            return None
    
    def detect_objects(self, thermal_image: np.ndarray) -> List[Dict]:
        """
        åœ¨çƒ­åŠ›å›¾ä¸Šè¿›è¡Œç›®æ ‡æ£€æµ‹
        
        Args:
            thermal_image: çƒ­åŠ›å›¾å›¾åƒ
            
        Returns:
            æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        try:
            if self.model is None:
                self.logger.error("æ¨¡å‹æœªåŠ è½½")
                return []
            
            # æ‰§è¡Œæ¨ç†
            results = self.model(
                thermal_image, 
                device=self.device,
                conf=self.confidence_threshold,
                iou=self.iou_threshold,
                max_det=self.max_detections
            )
            
            detections = []
            
            for result in results:
                if hasattr(result, 'obb') and result.obb is not None:
                    # æ—‹è½¬è¾¹ç•Œæ¡†æ£€æµ‹ç»“æœ
                    boxes = result.obb.xyxyxyxy.cpu().numpy()  # 8ç‚¹åæ ‡
                    confs = result.obb.conf.cpu().numpy()      # ç½®ä¿¡åº¦
                    classes = result.obb.cls.cpu().numpy()     # ç±»åˆ«
                    
                    for i, (box, conf, cls) in enumerate(zip(boxes, confs, classes)):
                        if conf > self.confidence_threshold:  # ä½¿ç”¨é…ç½®çš„ç½®ä¿¡åº¦é˜ˆå€¼
                            detections.append({
                                'box': box,
                                'confidence': float(conf),
                                'class_id': int(cls),
                                'class_name': 'electrical_equipment'
                            })
                
                elif hasattr(result, 'boxes') and result.boxes is not None:
                    # æ™®é€šè¾¹ç•Œæ¡†æ£€æµ‹ç»“æœ
                    boxes = result.boxes.xyxy.cpu().numpy()   # x1,y1,x2,y2
                    confs = result.boxes.conf.cpu().numpy()   # ç½®ä¿¡åº¦
                    classes = result.boxes.cls.cpu().numpy()  # ç±»åˆ«
                    
                    for i, (box, conf, cls) in enumerate(zip(boxes, confs, classes)):
                        if conf > 0.5:  # ç½®ä¿¡åº¦é˜ˆå€¼
                            detections.append({
                                'box': box,
                                'confidence': float(conf),
                                'class_id': int(cls),
                                'class_name': 'electrical_equipment'
                            })
            
            self.logger.info(f"æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡")
            return detections
            
        except Exception as e:
            self.logger.error(f"ç›®æ ‡æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def calculate_temperature_stats(self, temp_data: np.ndarray) -> Dict:
        """
        è®¡ç®—æ¸©åº¦ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            temp_data: æ¸©åº¦æ•°æ®çŸ©é˜µ
            
        Returns:
            æ¸©åº¦ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            stats = {
                'min_temp': float(np.min(temp_data)),
                'max_temp': float(np.max(temp_data)),
                'mean_temp': float(np.mean(temp_data)),
                'std_temp': float(np.std(temp_data)),
                'temp_range': float(np.max(temp_data) - np.min(temp_data))
            }
            
            # è®¡ç®—å¼‚å¸¸æ¸©åº¦ç‚¹ (è¶…è¿‡å‡å€¼+2å€æ ‡å‡†å·®)
            threshold = stats['mean_temp'] + 2 * stats['std_temp']
            hot_spots = np.sum(temp_data > threshold)
            stats['hot_spots_count'] = int(hot_spots)
            stats['hot_spots_ratio'] = float(hot_spots / temp_data.size)
            
            return stats
            
        except Exception as e:
            self.logger.error(f"æ¸©åº¦ç»Ÿè®¡è®¡ç®—å¤±è´¥: {e}")
            return {}
    
    def process_single_inference(self, sample_name: str) -> Dict:
        """
        å¤„ç†å•ä¸ªæ ·æœ¬çš„æ¨ç†
        
        Args:
            sample_name: æ ·æœ¬åç§°
            
        Returns:
            æ¨ç†ç»“æœä¿¡æ¯
        """
        try:
            self.logger.info(f"ğŸ” å¼€å§‹æ¨ç†: {sample_name}")
            
            # æ–‡ä»¶è·¯å¾„
            temp_file = os.path.join(self.config['paths']['data_root'], 'TEMPImages', f"{sample_name}.txt")
            jpg_file = os.path.join(self.config['paths']['data_root'], 'JPEGImages', f"{sample_name}.jpg")
            
            # 1. åŠ è½½æ¸©åº¦æ•°æ® (ä¸»è¦æ£€æµ‹æ•°æ®)
            temp_data = self.load_temperature_data(temp_file)
            if temp_data is None:
                return {"success": False, "error": "æ¸©åº¦æ•°æ®åŠ è½½å¤±è´¥"}
            
            # 2. è½¬æ¢ä¸ºçƒ­åŠ›å›¾
            thermal_image = self.convert_thermal_to_inference_image(temp_data)
            if thermal_image is None:
                return {"success": False, "error": "çƒ­åŠ›å›¾è½¬æ¢å¤±è´¥"}
            
            # 3. æ‰§è¡Œæ£€æµ‹ (åŸºäºæ¸©åº¦æ•°æ®)
            detections = self.detect_objects(thermal_image)
            
            # 4. è®¡ç®—æ¸©åº¦ç»Ÿè®¡
            temp_stats = self.calculate_temperature_stats(temp_data)
            
            # 5. åŠ è½½åŸå§‹å›¾åƒ (ä»…ç”¨äºå¯¹æ¯”å±•ç¤º)
            original_image = None
            if os.path.exists(jpg_file):
                original_image = cv2.imread(jpg_file)
                if original_image is not None:
                    target_size = tuple(self.config['data_processing']['input_size'])
                    original_image = cv2.resize(original_image, target_size)
            
            result = {
                "success": True,
                "sample_name": sample_name,
                "detections": detections,
                "temperature_stats": temp_stats,
                "thermal_image": thermal_image,
                "original_image": original_image,
                "detection_count": len(detections)
            }
            
            self.logger.info(f"âœ… æ¨ç†å®Œæˆ: {sample_name}, æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡")
            return result
            
        except Exception as e:
            self.logger.error(f"æ¨ç†å¤±è´¥ {sample_name}: {e}")
            return {"success": False, "error": str(e)}
    
    def save_detection_results_json(self, results: List[Dict], save_path: str = None) -> str:
        """
        ä¿å­˜æ£€æµ‹ç»“æœä¸ºJSONæ ¼å¼
        
        Args:
            results: æ¨ç†ç»“æœåˆ—è¡¨
            save_path: ä¿å­˜è·¯å¾„ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        try:
            if save_path is None:
                save_path = os.path.join(self.output_dir, 'inference_detection_results.json')
            
            # è½¬æ¢ç»“æœä¸ºå¯åºåˆ—åŒ–æ ¼å¼
            json_results = []
            for result in results:
                if result.get('success', False):
                    detections = []
                    for detection in result.get('detections', []):
                        # è½¬æ¢numpyæ•°ç»„ä¸ºåˆ—è¡¨
                        det_dict = {
                            'box': detection['box'].tolist() if hasattr(detection['box'], 'tolist') else detection['box'],
                            'confidence': float(detection['confidence']),
                            'class_id': int(detection['class_id']),
                            'class_name': detection['class_name']
                        }
                        detections.append(det_dict)
                    
                    json_result = {
                        'sample_name': result['sample_name'],
                        'detection_count': result['detection_count'],
                        'detections': detections,
                        'temperature_stats': result.get('temperature_stats', {})
                    }
                    json_results.append(json_result)
            
            # ä¿å­˜JSONæ–‡ä»¶
            with open(save_path, 'w', encoding='utf-8') as f:
                json.dump(json_results, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"âœ… æ£€æµ‹ç»“æœå·²ä¿å­˜: {save_path}")
            return save_path
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜JSONç»“æœå¤±è´¥: {e}")
            return None
    
    def batch_inference(self, sample_names: List[str] = None) -> List[Dict]:
        """
        æ‰¹é‡æ¨ç†
        
        Args:
            sample_names: æ ·æœ¬åç§°åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰æ ·æœ¬
            
        Returns:
            æ¨ç†ç»“æœåˆ—è¡¨
        """
        self.logger.info("ğŸš€ å¼€å§‹æ‰¹é‡æ¨ç†...")
        
        # è·å–æ ·æœ¬åˆ—è¡¨
        if sample_names is None:
            temp_dir = os.path.join(self.config['paths']['data_root'], 'TEMPImages')
            if not os.path.exists(temp_dir):
                self.logger.error(f"æ¸©åº¦æ•°æ®ç›®å½•ä¸å­˜åœ¨: {temp_dir}")
                return []
                
            temp_files = [f for f in os.listdir(temp_dir) if f.endswith('.txt')]
            sample_names = [os.path.splitext(f)[0] for f in temp_files]
        
        self.logger.info(f"å‘ç° {len(sample_names)} ä¸ªæ ·æœ¬")
        
        # æ‰¹é‡å¤„ç†
        results = []
        for sample_name in sample_names:
            result = self.process_single_inference(sample_name)
            results.append(result)
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r.get('success', False))
        total_detections = sum(r.get('detection_count', 0) for r in results if r.get('success', False))
        
        self.logger.info(f"ğŸ“Š æ‰¹é‡æ¨ç†å®Œæˆ: {success_count}/{len(sample_names)} æˆåŠŸ, æ€»æ£€æµ‹æ•°: {total_detections}")
        
        # è‡ªåŠ¨ä¿å­˜JSONç»“æœ
        if results:
            json_path = self.save_detection_results_json(results)
            if json_path:
                self.logger.info(f"ğŸ“„ æ£€æµ‹ç»“æœJSONå·²ä¿å­˜: {json_path}")
        
        return results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒ¡ï¸ UAV20241021 æ¸©åº¦æ•°æ®é©±åŠ¨æ¨ç† - å¯åŠ¨")
    print("=" * 50)
    print("ğŸ¯ æ ¸å¿ƒ: åŸºäºæ¸©åº¦æ•°æ®çš„è®¾å¤‡æ£€æµ‹")
    print("ğŸ“¸ è¾…åŠ©: åŸå§‹å›¾åƒä»…ç”¨äºæ•ˆæœå¯¹æ¯”")
    print("=" * 50)
    
    # åˆ›å»ºæ¨ç†å¼•æ“
    inference_engine = ThermalInferenceEngine()
    
    # æ‰§è¡Œæ‰¹é‡æ¨ç†
    results = inference_engine.batch_inference()
    
    if results:
        success_results = [r for r in results if r.get('success', False)]
        
        print(f"\nğŸ“Š æ¨ç†ç»Ÿè®¡:")
        print(f"  âœ… æˆåŠŸ: {len(success_results)}")
        print(f"  âŒ å¤±è´¥: {len(results) - len(success_results)}")
        print(f"  ğŸ¯ æ€»æ£€æµ‹æ•°: {sum(r.get('detection_count', 0) for r in success_results)}")
        
        if success_results:
            print(f"\nğŸ’¡ æ¨ç†ç»“æœå·²ä¿å­˜ï¼Œå¯è¿›è¡Œå¯è§†åŒ–å±•ç¤º")
            print(f"ğŸŒ¡ï¸ æ¸©åº¦é©±åŠ¨æ£€æµ‹ç³»ç»Ÿè¿è¡Œæ­£å¸¸")
        else:
            print(f"\nâš ï¸  è­¦å‘Š: æ‰€æœ‰æ¨ç†éƒ½å¤±è´¥äº†")
    else:
        print(f"\nâŒ æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„æ•°æ®")

if __name__ == "__main__":
    main()
